{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-100k.zip\n",
      "   creating: ml-100k/\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-04-17 12:02:58--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4924029 (4.7M) [application/zip]\n",
      "Saving to: ‘ml-100k.zip’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1%  637K 7s\n",
      "    50K .......... .......... .......... .......... ..........  2% 1.14M 6s\n",
      "   100K .......... .......... .......... .......... ..........  3% 72.6M 4s\n",
      "   150K .......... .......... .......... .......... ..........  4%  271M 3s\n",
      "   200K .......... .......... .......... .......... ..........  5% 1.15M 3s\n",
      "   250K .......... .......... .......... .......... ..........  6% 66.4M 2s\n",
      "   300K .......... .......... .......... .......... ..........  7%  175M 2s\n",
      "   350K .......... .......... .......... .......... ..........  8% 1.16M 2s\n",
      "   400K .......... .......... .......... .......... ..........  9%  117M 2s\n",
      "   450K .......... .......... .......... .......... .......... 10%  132M 2s\n",
      "   500K .......... .......... .......... .......... .......... 11%  185M 2s\n",
      "   550K .......... .......... .......... .......... .......... 12%  135M 1s\n",
      "   600K .......... .......... .......... .......... .......... 13%  105M 1s\n",
      "   650K .......... .......... .......... .......... .......... 14%  102M 1s\n",
      "   700K .......... .......... .......... .......... .......... 15%  156M 1s\n",
      "   750K .......... .......... .......... .......... .......... 16%  236M 1s\n",
      "   800K .......... .......... .......... .......... .......... 17% 1.20M 1s\n",
      "   850K .......... .......... .......... .......... .......... 18%  273M 1s\n",
      "   900K .......... .......... .......... .......... .......... 19%  150M 1s\n",
      "   950K .......... .......... .......... .......... .......... 20%  143M 1s\n",
      "  1000K .......... .......... .......... .......... .......... 21% 85.6M 1s\n",
      "  1050K .......... .......... .......... .......... .......... 22%  280M 1s\n",
      "  1100K .......... .......... .......... .......... .......... 23%  156M 1s\n",
      "  1150K .......... .......... .......... .......... .......... 24% 99.5M 1s\n",
      "  1200K .......... .......... .......... .......... .......... 25%  188M 1s\n",
      "  1250K .......... .......... .......... .......... .......... 27%  145M 1s\n",
      "  1300K .......... .......... .......... .......... .......... 28%  129M 1s\n",
      "  1350K .......... .......... .......... .......... .......... 29%  185M 1s\n",
      "  1400K .......... .......... .......... .......... .......... 30% 1.23M 1s\n",
      "  1450K .......... .......... .......... .......... .......... 31%  173M 1s\n",
      "  1500K .......... .......... .......... .......... .......... 32%  151M 1s\n",
      "  1550K .......... .......... .......... .......... .......... 33%  153M 1s\n",
      "  1600K .......... .......... .......... .......... .......... 34% 99.7M 1s\n",
      "  1650K .......... .......... .......... .......... .......... 35%  161M 1s\n",
      "  1700K .......... .......... .......... .......... .......... 36%  153M 1s\n",
      "  1750K .......... .......... .......... .......... .......... 37%  162M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 38%  111M 0s\n",
      "  1850K .......... .......... .......... .......... .......... 39%  102M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 40%  101M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 41%  263M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 42%  100M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 43%  129M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 44%  157M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 45%  119M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 46%  313M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 47%  104M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 48%  125M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 49%  154M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 50% 88.6M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 51%  135M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 53%  251M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 54%  110M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 55% 76.6M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 56%  162M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 57%  253M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 58%  284M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 59% 1.47M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 60% 94.2M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 61%  122M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 62%  156M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 63% 80.4M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 64%  172M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 65%  122M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 66%  195M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 67%  135M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 68% 75.8M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 69% 92.3M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 70% 52.9M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 71%  143M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 72% 60.5M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 73% 11.4M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 74%  261M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 75%  132M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 76%  264M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 77%  124M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 79%  149M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 80%  219M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 81%  311M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 82%  246M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 83%  306M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 84%  290M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 85%  312M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 86%  243M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 87%  265M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 88%  291M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 89%  293M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 90% 11.4M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 91% 1.93M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 92% 62.3M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 93% 73.8M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 94%  280M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 95% 62.0M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 96%  184M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 97% 62.2M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 98%  106M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 99%  316M 0s\n",
      "  4800K ........                                              100%  248M=0.4s\n",
      "\n",
      "2021-04-17 12:02:59 (12.2 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "unzip ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Chap-No-4(Factorization machine Algorithm)/ml-100k\n",
      "683\t312\t3\t893284183\n",
      "933\t166\t3\t874854062\n",
      "222\t8\t1\t878182307\n",
      "621\t559\t5\t874964915\n",
      "13\t519\t5\t882140355\n"
     ]
    }
   ],
   "source": [
    "%cd ml-100k\n",
    "!shuf ua.base -o ua.base.shuffled\n",
    "!head -5 ua.base.shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 943\n",
    "num_movies = 1682\n",
    "num_features = num_users+num_movies\n",
    "num_ratings_train = 90570\n",
    "num_ratings_test = 9430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(filename, lines, columns):\n",
    "    X = lil_matrix((lines, columns)).astype('float32')\n",
    "    Y = []\n",
    "    line=0\n",
    "    with open(filename,'r') as f:\n",
    "        samples=csv.reader(f,delimiter='\\t')\n",
    "        for userId,movieId,rating,timestamp in samples:\n",
    "            X[line,int(userId)-1] = 1\n",
    "            X[line,int(num_users)+int(movieId)-1] = 1\n",
    "            Y.append(int(rating))\n",
    "            line=line+1\n",
    "    Y=np.array(Y).astype('float32')\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = loadDataset('ua.base.shuffled',num_ratings_train,num_features)\n",
    "X_test, Y_test = loadDataset('ua.test',num_ratings_test,num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90570, 2625)\n",
      "(90570,)\n",
      "(9430, 2625)\n",
      "(9430,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, boto3\n",
    "import sagemaker.amazon.common as smac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeDatasetToProtobuf(X, Y, bucket, prefix, key):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "    buf.seek(0)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'fm-movielens'\n",
    "train_key = 'train.protobuf'\n",
    "train_prefix = '{}/{}'.format(prefix, 'train')\n",
    "test_key = 'test.protobuf'\n",
    "test_prefix = '{}/{}'.format(prefix, 'test')\n",
    "output_prefix = 's3://{}/{}/output'.format(bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = writeDatasetToProtobuf(X_train, Y_train,bucket, train_prefix, train_key)\n",
    "test_data = writeDatasetToProtobuf(X_test, Y_test,bucket, test_prefix, test_key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "region=boto3.Session().region_name\n",
    "container=image_uris.retrieve('factorization-machines',region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm=sagemaker.estimator.Estimator(\n",
    " container,\n",
    " role=sagemaker.get_execution_role(),\n",
    " instance_count=1,\n",
    " instance_type='ml.m5.xlarge',\n",
    " output_path=output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.set_hyperparameters(\n",
    " feature_dim=num_features,\n",
    " predictor_type='regressor',\n",
    " num_factors=64,\n",
    " epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-17 13:03:35 Starting - Starting the training job...\n",
      "2021-04-17 13:03:59 Starting - Launching requested ML instancesProfilerReport-1618664615: InProgress\n",
      "......\n",
      "2021-04-17 13:04:59 Starting - Preparing the instances for training...\n",
      "2021-04-17 13:05:36 Downloading - Downloading input data...\n",
      "2021-04-17 13:05:59 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/jsonref.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:87: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:120: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '2625', 'predictor_type': 'regressor', 'num_factors': '64', 'epochs': '10'}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] Final configuration: {'epochs': '10', 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '2625', 'predictor_type': 'regressor', 'num_factors': '64'}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 WARNING 140634086573888] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] Using default worker.\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:20.135] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:20.139] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 7, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] nvidia-smi: took 0.042 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664780.1317995, \"EndTime\": 1618664780.18809, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 50.13751983642578, \"count\": 1, \"min\": 50.13751983642578, \"max\": 50.13751983642578}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664780.188219, \"EndTime\": 1618664780.1882596, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 1000.0, \"count\": 1, \"min\": 1000, \"max\": 1000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[13:06:20] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.204642.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[13:06:20] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.204642.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=3.7407298178714403\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=13.9930595703125\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=3.5563681640625\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:20.805] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 597, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.7440978175737807\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] #quality_metric: host=algo-1, epoch=0, train mse <loss>=3.041877197265625\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=1.3825470614590487\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664780.1881676, \"EndTime\": 1618664780.8056586, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"update.time\": {\"sum\": 617.1724796295166, \"count\": 1, \"min\": 617.1724796295166, \"max\": 617.1724796295166}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664780.1884582, \"EndTime\": 1618664780.8059003, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 91570.0, \"count\": 1, \"min\": 91570, \"max\": 91570}, \"Total Batches Seen\": {\"sum\": 92.0, \"count\": 1, \"min\": 92, \"max\": 92}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] #throughput_metric: host=algo-1, train throughput=146664.91382409004 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.1532602287746845\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.3300091552734374\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:20 INFO 140634086573888] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=0.9771011962890624\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:21.471] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 663, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:21 INFO 140634086573888] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.1314871563279816\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:21 INFO 140634086573888] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.280263184935182\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:21 INFO 140634086573888] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.9467283130687671\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664780.8057375, \"EndTime\": 1618664781.4719248, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 665.4627323150635, \"count\": 1, \"min\": 665.4627323150635, \"max\": 665.4627323150635}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:21 INFO 140634086573888] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664780.8064384, \"EndTime\": 1618664781.47218, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 182140.0, \"count\": 1, \"min\": 182140, \"max\": 182140}, \"Total Batches Seen\": {\"sum\": 183.0, \"count\": 1, \"min\": 183, \"max\": 183}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:21 INFO 140634086573888] #throughput_metric: host=algo-1, train throughput=136019.01199177466 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:21 INFO 140634086573888] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.1374969415309157\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:21 INFO 140634086573888] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.2938992919921875\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:21 INFO 140634086573888] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=0.9633495483398438\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:22.199] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 724, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.1136177677243804\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.240144532591432\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.9299196884658311\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664781.4719884, \"EndTime\": 1618664782.2002861, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 727.445125579834, \"count\": 1, \"min\": 727.445125579834, \"max\": 727.445125579834}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664781.4728134, \"EndTime\": 1618664782.200493, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 272710.0, \"count\": 1, \"min\": 272710, \"max\": 272710}, \"Total Batches Seen\": {\"sum\": 274.0, \"count\": 1, \"min\": 274, \"max\": 274}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #throughput_metric: host=algo-1, train throughput=124442.16079941088 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.1191196142224924\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.2524287109375\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=0.9455169067382813\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:22.854] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 651, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.0945922348363546\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.1981321605640454\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.9110530013199691\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664782.200356, \"EndTime\": 1618664782.8549757, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 653.8221836090088, \"count\": 1, \"min\": 653.8221836090088, \"max\": 653.8221836090088}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664782.2011256, \"EndTime\": 1618664782.8551986, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 363280.0, \"count\": 1, \"min\": 363280, \"max\": 363280}, \"Total Batches Seen\": {\"sum\": 365.0, \"count\": 1, \"min\": 365, \"max\": 365}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #throughput_metric: host=algo-1, train throughput=138446.60925848986 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.0998288108091812\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.2096234130859376\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:22 INFO 140634086573888] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=0.9257017822265625\u001b[0m\n",
      "\n",
      "2021-04-17 13:06:37 Uploading - Uploading generated training model\n",
      "2021-04-17 13:06:37 Completed - Training job completed\n",
      "\u001b[34m[2021-04-17 13:06:23.478] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 621, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:23 INFO 140634086573888] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=1.0754714162248444\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:23 INFO 140634086573888] #quality_metric: host=algo-1, epoch=4, train mse <loss>=1.1566387671166725\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:23 INFO 140634086573888] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.8909531008542239\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664782.855047, \"EndTime\": 1618664783.4792945, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 623.5795021057129, \"count\": 1, \"min\": 623.5795021057129, \"max\": 623.5795021057129}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:23 INFO 140634086573888] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664782.8556898, \"EndTime\": 1618664783.4795294, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 453850.0, \"count\": 1, \"min\": 453850, \"max\": 453850}, \"Total Batches Seen\": {\"sum\": 456.0, \"count\": 1, \"min\": 456, \"max\": 456}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:23 INFO 140634086573888] #throughput_metric: host=algo-1, train throughput=145153.14301216812 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:23 INFO 140634086573888] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.0810210198291705\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:23 INFO 140634086573888] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.1686064453125\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:23 INFO 140634086573888] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=0.9052379150390625\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:24.075] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 593, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=1.0573208628725674\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #quality_metric: host=algo-1, epoch=5, train mse <loss>=1.1179274070655907\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.8707062324272408\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664783.479368, \"EndTime\": 1618664784.0756426, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 595.4396724700928, \"count\": 1, \"min\": 595.4396724700928, \"max\": 595.4396724700928}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664783.4801784, \"EndTime\": 1618664784.0757978, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 544420.0, \"count\": 1, \"min\": 544420, \"max\": 544420}, \"Total Batches Seen\": {\"sum\": 547.0, \"count\": 1, \"min\": 547, \"max\": 547}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #throughput_metric: host=algo-1, train throughput=152035.22957281602 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.063537981037525\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.131113037109375\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=0.8850061645507813\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:24.656] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 578, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=1.0407453261813275\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #quality_metric: host=algo-1, epoch=6, train mse <loss>=1.0831508339682778\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.8512821588201838\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664784.075699, \"EndTime\": 1618664784.656686, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 580.3818702697754, \"count\": 1, \"min\": 580.3818702697754, \"max\": 580.3818702697754}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664784.0762799, \"EndTime\": 1618664784.6568463, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 634990.0, \"count\": 1, \"min\": 634990, \"max\": 634990}, \"Total Batches Seen\": {\"sum\": 638.0, \"count\": 1, \"min\": 638, \"max\": 638}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #throughput_metric: host=algo-1, train throughput=155979.12546470005 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=1.0477785280057996\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=1.09783984375\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:24 INFO 140634086573888] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.8659030151367187\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:25.205] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 547, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=1.026012464669987\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #quality_metric: host=algo-1, epoch=7, train mse <loss>=1.0527015776581816\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.8337318497542496\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664784.656744, \"EndTime\": 1618664785.206322, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 548.9470958709717, \"count\": 1, \"min\": 548.9470958709717, \"max\": 548.9470958709717}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664784.6573498, \"EndTime\": 1618664785.2065272, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 725560.0, \"count\": 1, \"min\": 725560, \"max\": 725560}, \"Total Batches Seen\": {\"sum\": 729.0, \"count\": 1, \"min\": 729, \"max\": 729}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #throughput_metric: host=algo-1, train throughput=164889.53339520123 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=1.0338622218409956\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=1.06887109375\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.8492279663085938\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:25.800] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 592, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=1.0131660423869535\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #quality_metric: host=algo-1, epoch=8, train mse <loss>=1.0265054294460423\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.8187195635785113\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664785.20638, \"EndTime\": 1618664785.8009691, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 593.9285755157471, \"count\": 1, \"min\": 593.9285755157471, \"max\": 593.9285755157471}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664785.2070172, \"EndTime\": 1618664785.8011324, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 816130.0, \"count\": 1, \"min\": 816130, \"max\": 816130}, \"Total Batches Seen\": {\"sum\": 820.0, \"count\": 1, \"min\": 820, \"max\": 820}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #throughput_metric: host=algo-1, train throughput=152422.5969508107 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=1.021745141787141\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=1.043963134765625\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:25 INFO 140634086573888] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.83476806640625\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:26.365] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 562, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=1.002109015282399\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #quality_metric: host=algo-1, epoch=9, train mse <loss>=1.0042224785102594\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.8063301411723043\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #quality_metric: host=algo-1, train rmse <loss>=1.002109015282399\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #quality_metric: host=algo-1, train mse <loss>=1.0042224785102594\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #quality_metric: host=algo-1, train absolute_loss <loss>=0.8063301411723043\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664785.8010304, \"EndTime\": 1618664786.365716, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 564.0742778778076, \"count\": 1, \"min\": 564.0742778778076, \"max\": 564.0742778778076}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664785.801618, \"EndTime\": 1618664786.3659327, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 906700.0, \"count\": 1, \"min\": 906700, \"max\": 906700}, \"Total Batches Seen\": {\"sum\": 911.0, \"count\": 1, \"min\": 911, \"max\": 911}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #throughput_metric: host=algo-1, train throughput=160463.78491629552 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 WARNING 140634086573888] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664786.3657837, \"EndTime\": 1618664786.3682468, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 2.048969268798828, \"count\": 1, \"min\": 2.048969268798828, \"max\": 2.048969268798828}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] Saved checkpoint to \"/tmp/tmpk1xgfjjf/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:26.374] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 6238, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[2021-04-17 13:06:26.402] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 27, \"num_examples\": 10, \"num_bytes\": 603520}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664786.3745544, \"EndTime\": 1618664786.4023685, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9430.0, \"count\": 1, \"min\": 9430, \"max\": 9430}, \"Total Batches Seen\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Max Records Seen Between Resets\": {\"sum\": 9430.0, \"count\": 1, \"min\": 9430, \"max\": 9430}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 9430.0, \"count\": 1, \"min\": 9430, \"max\": 9430}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #test_score (algo-1) : ('rmse', 1.0172385840651914)\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #test_score (algo-1) : ('mse', 1.0347743369109557)\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #test_score (algo-1) : ('absolute_loss', 0.8354414356349003)\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #quality_metric: host=algo-1, test rmse <loss>=1.0172385840651914\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #quality_metric: host=algo-1, test mse <loss>=1.0347743369109557\u001b[0m\n",
      "\u001b[34m[04/17/2021 13:06:26 INFO 140634086573888] #quality_metric: host=algo-1, test absolute_loss <loss>=0.8354414356349003\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1618664786.368315, \"EndTime\": 1618664786.4031675, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 17.804384231567383, \"count\": 1, \"min\": 17.804384231567383, \"max\": 17.804384231567383}, \"totaltime\": {\"sum\": 6294.64316368103, \"count\": 1, \"min\": 6294.64316368103, \"max\": 6294.64316368103}}}\n",
      "\u001b[0m\n",
      "Training seconds: 61\n",
      "Billable seconds: 61\n"
     ]
    }
   ],
   "source": [
    "fm.fit({'train': train_data, 'test': test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------"
     ]
    }
   ],
   "source": [
    "endpoint_name = 'fm-movielens-100k'\n",
    "fm_predictor = fm.deploy(\n",
    " endpoint_name=endpoint_name,\n",
    " instance_type='ml.t2.medium',\n",
    " initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
